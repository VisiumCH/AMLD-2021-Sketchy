{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook enables to predict the closest images of a sketch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:00:33.115321Z",
     "start_time": "2021-02-22T15:00:32.452098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "plt.rcParams['axes.titlesize'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:00:33.659724Z",
     "start_time": "2021-02-22T15:00:33.125491Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data.loader_factory import load_data\n",
    "from src.data.utils import default_image_loader\n",
    "from src.models.encoder import EncoderCNN\n",
    "from src.models.utils import load_checkpoint\n",
    "from src.models.test import get_test_data\n",
    "from src.models.metrics import get_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:00:33.674200Z",
     "start_time": "2021-02-22T15:00:33.670769Z"
    }
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    dataset = \"sketchy_extend\"\n",
    "    data_path = \"../io/data/raw\"\n",
    "    emb_size = 256\n",
    "    grl_lambda = 0.5\n",
    "    nopretrain = False\n",
    "    epochs = 1000\n",
    "    batch_size = 10\n",
    "    seed = 42\n",
    "    load = None\n",
    "    early_stop = 20\n",
    "    ngpu = 1\n",
    "    prefetch = 2\n",
    "    log = \"../io/models/\"\n",
    "    log_interval = 20\n",
    "    attn = True\n",
    "    plot = False\n",
    "    cuda = False\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:00:33.861137Z",
     "start_time": "2021-02-22T15:00:33.854210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f562c969ad0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess embeddings to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:00:35.782486Z",
     "start_time": "2021-02-22T15:00:35.775466Z"
    }
   },
   "outputs": [],
   "source": [
    "BEST_CHECKPOINT = '../io/models/1_run-batch_size_10/checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:00:36.296377Z",
     "start_time": "2021-02-22T15:00:36.285913Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(args, best_checkpoint):\n",
    "    im_net = EncoderCNN(out_size=args.emb_size, attention=True)\n",
    "    sk_net = EncoderCNN(out_size=args.emb_size, attention=True)\n",
    "    \n",
    "    #checkpoint = load_checkpoint(best_checkpoint)\n",
    "    checkpoint = torch.load(best_checkpoint, map_location='cpu')\n",
    "    \n",
    "    im_net.load_state_dict(checkpoint['im_state'])\n",
    "    sk_net.load_state_dict(checkpoint['sk_state'])\n",
    "\n",
    "    if args.cuda and args.ngpu > 1:\n",
    "        print('\\t* Data Parallel **NOT TESTED**')\n",
    "        im_net = nn.DataParallel(im_net, device_ids=list(range(args.ngpu)))\n",
    "        sk_net = nn.DataParallel(sk_net, device_ids=list(range(args.ngpu)))\n",
    "\n",
    "    if args.cuda:\n",
    "        print('\\t* CUDA')\n",
    "        im_net, sk_net = im_net.cuda(), sk_net.cuda()\n",
    "\n",
    "    return im_net, sk_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_net, sk_net = get_model(args, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Image: 10453\n",
      "Classes: ['bat', 'cabin', 'cow', 'dolphin', 'door', 'giraffe', 'helicopter', 'mouse', 'pear', 'raccoon', 'rhinoceros', 'saw', 'scissors', 'seagull', 'skyscraper', 'songbird', 'sword', 'tree', 'wheelchair', 'windmill', 'window']\n",
      "0 images processed on 10453\n",
      "200 images processed on 10453\n",
      "400 images processed on 10453\n",
      "600 images processed on 10453\n",
      "800 images processed on 10453\n",
      "1000 images processed on 10453\n",
      "1200 images processed on 10453\n",
      "1400 images processed on 10453\n",
      "1600 images processed on 10453\n",
      "1800 images processed on 10453\n",
      "2000 images processed on 10453\n",
      "2200 images processed on 10453\n",
      "2400 images processed on 10453\n",
      "2600 images processed on 10453\n",
      "2800 images processed on 10453\n",
      "3000 images processed on 10453\n",
      "3200 images processed on 10453\n",
      "3400 images processed on 10453\n",
      "3600 images processed on 10453\n",
      "3800 images processed on 10453\n",
      "4000 images processed on 10453\n",
      "4200 images processed on 10453\n",
      "4400 images processed on 10453\n",
      "4600 images processed on 10453\n",
      "4800 images processed on 10453\n",
      "5000 images processed on 10453\n",
      "5200 images processed on 10453\n",
      "5400 images processed on 10453\n",
      "5600 images processed on 10453\n",
      "5800 images processed on 10453\n",
      "6000 images processed on 10453\n",
      "6200 images processed on 10453\n",
      "6400 images processed on 10453\n",
      "6600 images processed on 10453\n",
      "6800 images processed on 10453\n",
      "7000 images processed on 10453\n",
      "7200 images processed on 10453\n",
      "7400 images processed on 10453\n",
      "7600 images processed on 10453\n",
      "7800 images processed on 10453\n",
      "8000 images processed on 10453\n",
      "8200 images processed on 10453\n",
      "8400 images processed on 10453\n",
      "8600 images processed on 10453\n",
      "8800 images processed on 10453\n",
      "9000 images processed on 10453\n",
      "9200 images processed on 10453\n",
      "9400 images processed on 10453\n",
      "9600 images processed on 10453\n",
      "9800 images processed on 10453\n",
      "10000 images processed on 10453\n",
      "10200 images processed on 10453\n"
     ]
    }
   ],
   "source": [
    "_, [_, _], [_, test_im_data], dict_class = load_data(args, transform)\n",
    "print(\"Length Image: {}\".format(len(test_im_data)))\n",
    "print(\"Classes: {}\".format(test_sk_data.get_class_dict()))\n",
    "\n",
    "test_im_loader = DataLoader(test_im_data, batch_size=1)\n",
    "images_fnames, images_embeddings, images_classes = get_test_data(test_im_loader, im_net, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[images_fnames, images_embeddings, images_classes]).T\n",
    "df.columns=['fnames', 'embeddings', 'classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../io/data/processed/images_embeddings.csv', sep=' ', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:00:40.496154Z",
     "start_time": "2021-02-22T15:00:40.492092Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_data(data_loader, model, args):\n",
    "    fnames = []\n",
    "    for i, (image, fname, target) in enumerate(data_loader):\n",
    "        if i%500 == 0:\n",
    "            print(f'{i} images processed on {len(data_loader)}')\n",
    "        # Process\n",
    "        out_features, _ = model(image)\n",
    "\n",
    "        # Filename of the images for qualitative\n",
    "        fnames.append(fname)\n",
    "\n",
    "        if i == 0:\n",
    "            embeddings = out_features.detach().numpy()\n",
    "            classes = target.detach().numpy()\n",
    "        else:\n",
    "            embeddings = np.concatenate((embeddings, out_features.detach().numpy()), axis=0)\n",
    "            classes = np.concatenate((classes, target.detach().numpy()), axis=0)\n",
    "\n",
    "    return fnames, embeddings, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:01:03.053569Z",
     "start_time": "2021-02-22T15:01:03.031418Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inference():\n",
    "    \n",
    "    def __init__(self, model_path, embedding_path):\n",
    "        \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.loader = default_image_loader\n",
    "        \n",
    "        self.im_net, self.sk_net = get_model(args, model_path)\n",
    "        \n",
    "        df = pd.read_csv(embedding_path, sep=' ', header=True)\n",
    "        self.images_fnames = df['fnames'].values\n",
    "        self.images_embeddings = df['embeddings'].values\n",
    "        self.images_classes = df['classes'].values\n",
    "        \n",
    "        \n",
    "    def inference_sketch(self, sketch_fname, plot=True):\n",
    "        ''' For now just process a sketch but TODO decide how to proceed later'''\n",
    "        \n",
    "        sketch = self.transform(self.loader(sketch_fname)).unsqueeze(0) # unsqueeze because 1 sketch (no batch)\n",
    "        sketch_embedding, _ = self.sk_net(sketch)\n",
    "        self.get_closest_images(sketch_embedding)\n",
    "        \n",
    "        if plot:\n",
    "            self.plot_closest(sketch_fname)\n",
    "        \n",
    "    def get_closest_images(self, sketch_embedding):\n",
    "        '''\n",
    "        Based on a sketch embedding, retrieve the index of the closest images\n",
    "        '''\n",
    "        \n",
    "        similarity = get_similarity(sketch_embedding, self.images_embeddings)\n",
    "        arg_sorted_sim = (-similarity).argsort()\n",
    "        \n",
    "        self.sorted_fnames = [self.images_fnames[i][0] for i in arg_sorted_sim[0]]\n",
    "        \n",
    "    def plot_closest(self, sketch_fname):\n",
    "        fig, axes = plt.subplots(1, NUM_CLOSEST + 1)\n",
    "\n",
    "        sk = mpimg.imread(sketch_fname)\n",
    "        axes[0].imshow(sk)\n",
    "        axes[0].set(title='Sketch')\n",
    "\n",
    "        for i in range(1, NUM_CLOSEST + 1):\n",
    "            im = mpimg.imread(self.sorted_fnames[i-1])\n",
    "            axes[i].imshow(im)\n",
    "            axes[i].set(title='Closest image ' + str(i))\n",
    "\n",
    "        plt.subplots_adjust(wspace=0.25, hspace=-0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:01:11.419960Z",
     "start_time": "2021-02-22T15:01:03.368087Z"
    }
   },
   "outputs": [],
   "source": [
    "inference = Inference(BEST_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:01:12.188282Z",
     "start_time": "2021-02-22T15:01:11.513836Z"
    }
   },
   "outputs": [],
   "source": [
    "sketch_fname = '../io/data/raw/Sketchy/sketch/tx_000000000000/bat/n02139199_1332-1.png'\n",
    "inference.inference_sketch(sketch_fname, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch_fname = '../io/data/raw/Sketchy/sketch/tx_000000000000/door/n03222176_681-1.png'\n",
    "inference.inference_sketch(sketch_fname, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch_fname = '../io/data/raw/Sketchy/sketch/tx_000000000000/giraffe/n02439033_67-1.png'\n",
    "inference.inference_sketch(sketch_fname, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch_fname = '../io/data/raw/Sketchy/sketch/tx_000000000000skyscraper/n04233124_498-1.png'\n",
    "inference.inference_sketch(sketch_fname, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch_fname = '../io/data/raw/Sketchy/sketch/tx_000000000000/wheelchair/n04576002_150-2.png'\n",
    "inference.inference_sketch(sketch_fname, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMLD env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
